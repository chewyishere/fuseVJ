Avsys+SensemakerFinal
===========

collaboration of Chewy, Yinan and Firm

A series of performance tools for audio/visual performance jamming

The project is also aimed to empowered audience to be able to jam with Audio/Visual performance via smartphone device. 

Imagine each phone as a particle or pixel that each participant can control a subtle movement of an assigned particle/pixel by their movement (dancing/waving phone, feeding accellerometer data to centralized source via OSC or through internet server.) The data from participants also can be served as a readymade data for performers/dj/vj to jam with the data freely by plug it in to different visual/sonic properties. 

The data stored after the event can also served as a readymade source for data visualization or even simulation of the event itself. As Joe Saavedra called it: " Internet of Parties. "


PARTIes

PARTIcles

PARTIcipants


1. oscRecieverAbleton --> Music control Visual (original panel disabled,
since I don't know how to change values into the slider so I faked another Ableton panel to show the values)  

2. oscSenderAbleton --> Visual control Music 

3. OpenCV test: try to effect RepulsionForce and FlockingForce with gesture. (Not sure how?) 

Question:
How to combine with Kinect / OpenCV so people can interactive / contain the visual from their body??
